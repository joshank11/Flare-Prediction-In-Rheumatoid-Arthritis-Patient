{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30dd32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.22.4 in c:\\users\\pshas\\anaconda3\\lib\\site-packages (1.22.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.22.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "588c913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a044fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded preprocessed data.\n",
      "[INFO] Feature shape: (9120, 180), Label shape: (9120,)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# STEP 1: Load Preprocessed Data\n",
    "# -----------------------------\n",
    "output_dir = r\"C:\\Users\\pshas\\OneDrive\\Desktop\\AcademicResearch\\IITBombay\\placement\\DreptoAIML\\Project-1\\outputs\"\n",
    "X = np.load(os.path.join(output_dir, \"preprocessed_features.npy\"))\n",
    "y = np.load(os.path.join(output_dir, \"simulated_labels.npy\"))\n",
    "\n",
    "print(\"[INFO] Loaded preprocessed data.\")\n",
    "print(f\"[INFO] Feature shape: {X.shape}, Label shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4686b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (5836, 180) (5836,)\n",
      "Validation: (1460, 180) (1460,)\n",
      "Test: (1824, 180) (1824,)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# STEP 2: Train-Test Split\n",
    "# -----------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: Temp (train+val) vs Test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Second split: Train vs Val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation:\", X_val.shape, y_val.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# Save for reuse in model_test.py\n",
    "# -----------------------------\n",
    "np.save(os.path.join(output_dir, \"X_train.npy\"), X_train)\n",
    "np.save(os.path.join(output_dir, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(output_dir, \"X_val.npy\"), X_val)\n",
    "np.save(os.path.join(output_dir, \"y_val.npy\"), y_val)\n",
    "np.save(os.path.join(output_dir, \"X_test.npy\"), X_test)\n",
    "np.save(os.path.join(output_dir, \"y_test.npy\"), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e88ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# STEP 3: Build MLP Model\n",
    "# -----------------------------\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b4339a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "292/292 [==============================] - 1s 2ms/step - loss: 0.7302 - accuracy: 0.4942 - val_loss: 0.6924 - val_accuracy: 0.5154\n",
      "Epoch 2/100\n",
      "292/292 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.5032 - val_loss: 0.6923 - val_accuracy: 0.5086\n",
      "Epoch 3/100\n",
      "292/292 [==============================] - 1s 2ms/step - loss: 0.6979 - accuracy: 0.5094 - val_loss: 0.6971 - val_accuracy: 0.4795\n",
      "Epoch 4/100\n",
      "292/292 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5013 - val_loss: 0.6982 - val_accuracy: 0.4735\n",
      "Epoch 5/100\n",
      "292/292 [==============================] - 1s 2ms/step - loss: 0.6949 - accuracy: 0.5034 - val_loss: 0.6944 - val_accuracy: 0.4760\n",
      "Epoch 6/100\n",
      "292/292 [==============================] - 1s 2ms/step - loss: 0.6938 - accuracy: 0.4979 - val_loss: 0.6928 - val_accuracy: 0.4837\n",
      "Epoch 7/100\n",
      "292/292 [==============================] - 1s 2ms/step - loss: 0.6935 - accuracy: 0.5013 - val_loss: 0.6933 - val_accuracy: 0.4743\n",
      "Epoch 8/100\n",
      "292/292 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.5054 - val_loss: 0.6937 - val_accuracy: 0.4803\n",
      "Epoch 9/100\n",
      "292/292 [==============================] - 1s 2ms/step - loss: 0.6936 - accuracy: 0.5154 - val_loss: 0.6946 - val_accuracy: 0.4760\n",
      "Epoch 10/100\n",
      "292/292 [==============================] - 1s 2ms/step - loss: 0.6937 - accuracy: 0.5077 - val_loss: 0.6938 - val_accuracy: 0.4726\n",
      "Epoch 11/100\n",
      "292/292 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6940 - val_accuracy: 0.4752\n",
      "Epoch 12/100\n",
      "292/292 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5064 - val_loss: 0.6937 - val_accuracy: 0.4743\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# STEP 4: Train Model\n",
    "# -----------------------------\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c969c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] Test Accuracy: 0.4973\n",
      "57/57 [==============================] - 0s 1ms/step\n",
      "57/57 [==============================] - 0s 875us/step\n",
      "[EXTENDED METRICS]\n",
      "Precision: 0.4982\n",
      "Recall: 0.7741\n",
      "F1-Score: 0.6063\n",
      "ROC-AUC: 0.4849\n",
      "\n",
      "[CLASSIFICATION REPORT]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.22      0.30       912\n",
      "           1       0.50      0.77      0.61       912\n",
      "\n",
      "    accuracy                           0.50      1824\n",
      "   macro avg       0.50      0.50      0.46      1824\n",
      "weighted avg       0.50      0.50      0.46      1824\n",
      "\n",
      "\n",
      "[CONFUSION MATRIX]\n",
      "[[201 711]\n",
      " [206 706]]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# STEP 5: Evaluate Model\n",
    "# -----------------------------\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 1. Basic Evaluation\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"[RESULT] Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 2. Generate predictions\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "y_pred_proba = model.predict(X_test)  # Probabilities for ROC-AUC\n",
    "\n",
    "# 3. Calculate additional metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "\n",
    "print(f\"[EXTENDED METRICS]\")\n",
    "print(f\"Precision: {precision:.4f}\")  # True positives / (True positives + False positives)\n",
    "print(f\"Recall: {recall:.4f}\")       # True positives / (True positives + False negatives)\n",
    "print(f\"F1-Score: {f1:.4f}\")         # Harmonic mean of precision and recall\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")     # Area under ROC curve (1.0 = perfect)\n",
    "\n",
    "# 4. Classification report\n",
    "print(\"\\n[CLASSIFICATION REPORT]\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 5. Confusion matrix\n",
    "\n",
    "clf_report = classification_report(y_test, y_pred)  # <-- Now properly defined\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\n[CONFUSION MATRIX]\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da554d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model and plots saved to C:\\Users\\pshas\\OneDrive\\Desktop\\AcademicResearch\\IITBombay\\placement\\DreptoAIML\\Project-1\\outputs/\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# STEP 6: Save Model & Plots\n",
    "# -----------------------------\n",
    "model.save(os.path.join(output_dir, \"mlp_model.h5\"))\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, \"loss_curve.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, \"accuracy_curve.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Plot and save confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig(os.path.join(output_dir, 'test_confusion_matrix.png'))\n",
    "plt.close()\n",
    "\n",
    "print(f\"[INFO] Model and plots saved to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b65a645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SAVED] ROC curve saved to C:\\Users\\pshas\\OneDrive\\Desktop\\AcademicResearch\\IITBombay\\placement\\DreptoAIML\\Project-1\\outputs\\roc_curve.png\n"
     ]
    }
   ],
   "source": [
    "#Test Plots\n",
    "\n",
    "# Save Numerical Metrics to a .txt file\n",
    "with open(os.path.join(output_dir, 'test_metrics.txt'), 'w') as f:\n",
    "    f.write(f\"Test Accuracy: {accuracy:.4f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "    f.write(f\"F1-Score: {f1:.4f}\\n\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(clf_report)\n",
    "    f.write(\"\\nConfusion Matrix:\\n\")\n",
    "    f.write(np.array2string(cm))\n",
    "\n",
    "# 6. Plot ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "         label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Save ROC plot\n",
    "roc_path = os.path.join(output_dir, 'roc_curve.png')\n",
    "plt.savefig(roc_path, bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\n[SAVED] ROC curve saved to {roc_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58077a51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
